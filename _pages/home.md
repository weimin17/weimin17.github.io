---
permalink: /
author_profile: True
share: false
layout: single
classes: wide
---



<style>a{TEXT-DECORATION:none; color: #990000;}a:hover{TEXT-DECORATION:underline; color: #990000;}</style>

## About Me


Hi! I am Weimin Lyu, a final year Ph.D. candidate in Computer Science at <a href="https://www.cs.stonybrook.edu/" target="_blank" rel="nofollow">Stony Brook University</a>, advised by <a href="https://chaochen.github.io/index.html" target="_blank" rel="nofollow">Prof. Chao Chen</a>. I have also been fortunate to collaborate with Professors
<a href="https://www3.cs.stonybrook.edu/~hling/" target="_blank" rel="nofollow">Haibin Ling</a>, 
<a href="https://www3.cs.stonybrook.edu/~fuswang/" target="_blank" rel="nofollow">Fusheng Wang</a>, and
<a href="https://sites.google.com/site/matf0123/" target="_blank" rel="nofollow">Tengfei Ma</a>. 
<!-- I am currently an Applied Scientist Intern at Amazon, focusing on foundation model (LLaMA, Mistral) continuously pre-training and fine-tuning with a strong emphasis on numerical and text features. -->





## Research Interests

My research centers on building safe, efficient, and interpretable AI systems across language, vision, and multimodal domains:

- <b>AI Security & Trustworthiness</b>: Backdoor attack and detection techniques for Language Models (e.g., BERT variations), Vision Models (e.g., ViT) and Vision-Language Models (e.g., CLIP, BLIP-2, LLaVA, etc).
- <b>Efficient Multimodal Learning</b>: Token compression and resource-efficient model design for whole slide pathology image analysis using vision-language models like LLaVA.
- <b>Model Explainability in Clinical AI</b>: Interpretable modeling of electronic health records using transformers and multimodal fusion.
- <b>LLM-based Personalization</b>: Designing and deploying end-to-end infrastructure for online personalized navigation models, with a focus on LLMs training, real-time signal compression, and customer understanding within Amazon shopping experience.


<!-- 
2025.08.01 before
My research focuses on model safety across a range of applications, including text-based problems (BERT variants, LLMs), image classification (CNNs, Vision Transformers, CLIP), and multimodal image-to-text generation with Vision-Language Models (BLIP-2, MiniGPT-4, LLaVA, InstructBLIP). I also specialize in explainability for clinical language models using Electronic Health Records.
 -->

<!-- My research focuses on understanding the mechanisms of deep learning models and developing algorithms to intentionally train models for specific behaviors, such as backdoor attack and defense strategies. Application areas span across Natural Language Processing and Computer Vision, including BERT variants, Vision Transformers (ViTs), and Vision-Language Models. I also have industry experience in training Large Language Foundation Models, and experience in explainability for clinical decision-making with Electronic Health Records (EHR).
 -->


<!-- My research mainly focuses on <b>Trustworthy AI</b>, especially backdoor attacks/defenses. My goal is to <b>enhance the security of Deep Learning-based models throughout their entire life cycle</b>. The application areas include different tasks across Natural Language Processing and Computer Vision. Experience on explainability in Healthcare and clinical decision making with EHR. Recently I focus on <b>Vision-Language Understanding</b> and <b>Large Language Models</b>. -->




## News
- 2025-05: Two papers accepted to ACL 2025! Congrats to all collaborators! [CalD](https://aclanthology.org/2025.acl-long.1424/), led by Chenlu and [Prof. Ritwik Banerjee](https://www.ritwikbanerjee.com/), proposes an efficient framework for detecting deviant or nuanced language using smaller models. [RPA Evaluation](https://aclanthology.org/2025.findings-acl.938/), led by Chaoran, Bingsheng and [Prof. Dakuo Wang](https://www.dakuowang.com/), presents a comprehensive guideline for evaluating LLM-based role-playing agents.
- 2025-01: Three papers are accepted by [ICLR 2025](https://iclr.cc/), including one first-authored paper: VLOOD! 
- 2024-07: My first-authored paper, TrojVLM, is accepted by [ECCV 2024](https://eccv2024.ecva.net/)! We investigate the vulnerabilities in the generative capabilities of Vision-Language Models, with a focus on image captioning and visual question answering (VQA) tasks.
- 2024-07: One paper is accepted by WACV 2025!
- 2024-06: My first-authored paper, BadCLM, is nominated as the Best Student Paper by [AMIA 2024](https://amia.org/education-events/annual-symposium)! We investigate the clinical language model's vulnerabilities. 
- 2024-03: One first-authored paper is accepted by [NAACL 2024](https://2024.naacl.org/)! We introduce a task-agnostic method for detecting textual backdoors, targeting a range of language models and traditional NLP tasks. 
- 2023-10: My first-authored [TAL](https://aclanthology.org/2023.findings-emnlp.716.pdf) is accepted by [EMNLP 2023](https://2023.emnlp.org/)!
- 2023-03: Two papers are accepted by [ICLR 2023 Workshop on BANDS](https://iclr23-bands.github.io/)!
- 2022-10: Paper "[An Integrated LSTM-HeteroRGNN Model for Interpretable Opioid Overdose Risk Prediction](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9630306/)" is accepted by [Artificial Intelligence in Medicine](https://www.sciencedirect.com/journal/artificial-intelligence-in-medicine)! 
- 2022-06: One first-authored [paper](https://arxiv.org/abs/2208.10240) is nominated as the Best Student Paper by [AMIA 2022](https://amia.org/education-events/annual-symposium)! We propose a multimodal transformer to fuse clinical notes and traditional EHR data for interpretable mortality prediction. AMIA is the world's premier meeting for research and practice of biomedical and health informatics.
- 2022-04: One first-authored paper "[A Study of the Attention Abnormality in Trojaned BERTs](https://aclanthology.org/2022.naacl-main.348/)" is accepted by [NAACL 2022](https://2022.naacl.org/)! 
- 2020-09: Start my Computer Science Ph.D. journey at Stony Brook University!


<!-- 
- 2022-11: Attended NeruIPS 2022 ~~at New Orleans, LA~~ remotely.
- 2022-11: Attended AMIA Symposium 2022 at Washington D.C., DC.
- 2022-07: Attended NAACL 2022 at Seattle, WA.
- 2022-06: Attended CVPR 2022 at New Orleans, LA.

 -->



## Industry Experience


<div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto; ustify-content: center; align-items: center;">
	<img title="amazon" style="float: left; padding-right: 1.5em; padding-down: 1.5em; padding-up: 1.5em; width: 150px; max-height: 300px;" src="/images/industry/amazon.jpeg">
		<div>
			Amazon, Seattle, USA (May 2025 - Present)<br>
			Applied Scientist<br>
			<br>
			- Currently working on LLM-based personalization solutions to enhance customer understanding and improve navigation relevance within Amazon's shopping experience.<br>
			- Focus areas include building end-to-end modeling and training infrastructure for personalized navigation models in an online setting, and data-driven personalization signals compression.<br>
		</div>
	</div>
</div>




<div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto; ustify-content: center; align-items: center;">
	<img title="amazon" style="float: left; padding-right: 1.5em; padding-down: 1.5em; padding-up: 1.5em; width: 150px; max-height: 300px;" src="/images/industry/amazon.jpeg">
		<div>
			Amazon, Seattle, USA (May 2024 - May 2025)<br>
			Applied Scientist Intern<br>
			<br>
			- Led the development of the first-generation seller foundation model, a transformer decoder-based LLM designed for seller-related data, with a strong emphasis on tabular inputs and numerical formats.<br>
            - Proposed and implemented an end-to-end two-stage training pipeline, including continuous pre-training (LM loss + attribution-level contrastive loss) and downstream fine-tuning (classification, multi-task, regression).<br>
            - Built the full modeling and training infrastructure, supporting 355M and 7B model training.<br>
            - Delivered production-ready model now running in shadow mode, pre-staged for full launch.<br>
		</div>
	</div>
</div>



<!-- 
<div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto; ustify-content: center; align-items: center;">
	<img title="yidutech" style="float: left; padding-right: 1.5em; padding-down: 1.5em; padding-up: 1.5em; width: 150px; max-height: 300px;" src="/images/industry/yidutech2.jpeg">
		<div>
			<b><a href="https://www.yidutechgroup.com/en/index.html" target="_blank" rel="nofollow">Yidu Tech Inc.</a></b> (Top 10 Artificial Intelligence Enterprises in China (2020)), Beijing, China (Aug 2018 - Aug 2020)<br>
			Consultant (Software Development Engineer)<br>
			- Smart finger ring developer (Build a sleep lab on your finger!)<br>
            - Develop a sleep tracker: in-depth analysis about your deep sleep, light sleep, blood oxygen levels, heart rate trend, and more<br>
            - Process Photoplethysmography (PPG) signal and movement tracks during sleeping<br>
  
		</div>
	</div>
</div> -->


<!-- 
<div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto; ustify-content: center; align-items: center;">
	<img title="k2data" style="float: left; padding-right: 1.5em; width: 150px; max-height: 150px;" src="/images/industry/k2data.png">
		<div>
			<b><a href="https://www.k2data.com.cn/" target="_blank" rel="nofollow">K2Data</a></b> (Top 50 AI Company in China (2020)), Beijing, China (May 2018 - Aug 2018)<br>
			Machine Learning Intern<br>
			- Serve as the core member in a three-people team; Implement Object Detection (Helmet-Detection Problem) algorithms, and the algorithm has been deployed in over 2,000 factories.<br>
			- Design and implement applications for object detection in real-time video<br>
            - Increase performance of safety helmet detection to 90% in industry level<br>
            - Main contributor in a 3-people team; the algorithm has been deployed in over 2,000 factories<br>
		</div>
	</div>
</div>
 -->






## Selected Publications

Full publications can be found in [Google Scholar](https://scholar.google.com/citations?user=IVed47cAAAAJ&hl=en).

<!-- ### Preprint -->




<!-- 
<div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto;">
	<img title="TechReport1" style="float: left; padding-right: 1.5em; width: 300px; max-height: 100px;" src="/images/pub/tech2022_1.png">
		<div>
			<b>Attention Hijacking in Trojan Transformers</b><br>
			<u>Weimin Lyu</u>, Songzhu Zheng, Tengfei Ma, Haibin Ling, Chao Chen<br>
			<em>Tech Report</em><br>
			[<a href="https://arxiv.org/abs/2208.04946" target="_blank" rel="nofollow">arXiv</a>]<br>
		</div>
	</div>
</div> -->






### Conference/Workshop/Journal 
<!-- keep its original aspect ratio while fitting into a consistent bounding box size -->

<!-- ArXiv -->
<!-- <div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto;">
	<img title="ICLR2025" style="float: left; margin-top: 40px; padding-right: 1.5em; width: 200px; max-height: 80px;" src="/images/pub/tech2025_1.jpg">
		<div> -->
<div style="margin-bottom: 0em; display: flex; flex-wrap: wrap; align-items: center; background-color: #fff; border: 0;">
	<div style="width: 300px; height: 100px; display: flex; align-items: center; justify-content: center; margin-right: 0.1em;">
		<img src="/images/pub/tech2025_1.jpg" alt="ICLR2025" title="ICLR2025"
         style="max-width: 100%; max-height: 100%; object-fit: contain;" />
	</div>
	<div style="flex: 1; min-width: 200px;">
			<b>Efficient Whole Slide Pathology VQA via Token Compression</b><br>
			<u>Weimin Lyu</u>, Qingqiao Hu, Kehan Qi, Zhan Shi, Wentao Huang, Saumya Gupta, Chao Chen<br>
			<em>In Submission</em><br>
			<a href="https://arxiv.org/pdf/2507.14497" target="_blank" rel="ArXiv">[ArXiv]</a><br>
	</div>
</div>


---


<!-- ACL2025-1-->
<!-- <div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto;">
	<img title="ACL2025" style="float: left; margin-top: 40px; padding-right: 1.5em; width: 200px; max-height: 80px;" src="/images/pub/acl2025_1_CalD.png">
		<div>
 -->
 <div style="margin-bottom: 0em; display: flex; flex-wrap: wrap; align-items: center; background-color: #fff; border: 0;">
	<div style="width: 300px; height: 100px; display: flex; align-items: center; justify-content: center; flex-shrink: 0; margin-right: 0.1em;">
		<img src="/images/pub/acl2025_1_CalD.png" alt="ACL2025" title="ACL2025"
         style="max-width: 100%; max-height: 100%; object-fit: contain;" />
	</div>
	<div style="flex: 1; min-width: 200px;">
			<b>Class Distillation with Mahalanobis Contrast: An Efficient Training Paradigm for Pragmatic Language Understanding Tasks</b><br>
			Chenlu Wang, <u>Weimin Lyu</u>, Ritwik Banerjee<br>
			<em>Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (<b>ACL 2025</b>)</em><br>
			<a href="https://aclanthology.org/2025.acl-long.1424/" target="_blank" rel="ACL">[ACL]</a><br>
	</div>
</div>


---


<!-- ACL2025-2-->
<!-- <div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto;">
	<img title="ACL2025" style="float: left; margin-top: 40px; padding-right: 1.5em; width: 300px; max-height: 100px;" src="/images/pub/acl2025_2_RPA.jpg">
		<div> -->
<div style="margin-bottom: 0em; display: flex; flex-wrap: wrap; align-items: center; background-color: #fff; border: 0;">
	<div style="width: 300px; height: 100px; display: flex; align-items: center; justify-content: center; flex-shrink: 0; margin-right: 0.1em;">
		<img src="/images/pub/acl2025_2_RPA.jpg" alt="ACL2025" title="ACL2025"
         style="max-width: 100%; max-height: 100%; object-fit: contain;" />
	</div>
	<div style="flex: 1; min-width: 200px;">
			<b>Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents</b><br>
			Chaoran Chen, Bingsheng Yao, Ruishi Zou, Wenyue Hua, <u>Weimin Lyu</u>, Toby Jia-Jun Li, Dakuo Wang<br>
			<em>Findings of the Association for Computational Linguistics: ACL 2025 (<b>ACL 2025</b>)</em><br>
			<a href="https://aclanthology.org/2025.findings-acl.938/" target="_blank" rel="ACL">[ACL]</a><br>
	</div>
</div>




---



<!-- ICLR2025-3 -->
<div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto;">
	<img title="ICLR2025" style="float: left; margin-top: 40px; padding-right: 1.5em; width: 300px; max-height: 100px;" src="/images/pub/iclr_3_lingjie.png">
		<div>
			<b>Geometry of Long-Tailed Representation Learning: Rebalancing Features for Skewed Distributions</b><br>
			Lingjie Yi, Jiachen Yao, <u>Weimin Lyu</u>, Haibin Ling, Raphael Douady, Chao Chen<br>
			<em>The Thirteenth International Conference on Learning Representations (<b>ICLR 2025</b>)</em><br>
			<a href="https://openreview.net/pdf?id=GySIAKEwtZ" target="_blank" rel="ICLR">[ICLR]</a><br>
		</div>
	</div>
</div>


---


<!-- ICLR2025-2 -->
<div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto;">
	<img title="ICLR2025" style="float: left; margin-top: 40px; padding-right: 1.5em; width: 300px; max-height: 100px;" src="/images/pub/iclr_2_impscore.jpg">
		<div>
			<b>ImpScore: A Learnable Metric For Quantifying The Implicitness Level of Language</b><br>
			Yuxin Wang, Xiaomeng Zhu*, <u>Weimin Lyu*</u>, Saeed Hassanpour, Soroush Vosoughi<br>
			<em>The Thirteenth International Conference on Learning Representations (<b>ICLR 2025</b>)(<b style="color:red;">Spotlight</b>)</em><br>
			<a href="https://openreview.net/pdf?id=gYWqxXE5RJ" target="_blank" rel="ICLR">[ICLR]</a><br>

		</div>
	</div>
</div>





---




<!-- ICLR2025 -->
<div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto;">
	<img title="ICLR2025" style="float: left; margin-top: 40px; padding-right: 1.5em; width: 300px; max-height: 100px;" src="/images/pub/tech2024_1.jpg">
		<div>
			<b>Backdooring Vision-Language Models with Out-Of-Distribution Data</b><br>
			<u>Weimin Lyu</u>, Jiachen Yao, Saumya Gupta, Lu Pang, Tao Sun, Lingjie Yi, Lijie Hu, Haibin Ling, Chao Chen<br>
			<em>The Thirteenth International Conference on Learning Representations (<b>ICLR 2025</b>)</em><br>
			<a href="https://openreview.net/pdf?id=tZozeR3VV7" target="_blank" rel="ICLR">[ICLR]</a><br>

		</div>
	</div>
</div>


---


<!-- WACV2025 -->
<div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto; ustify-content: center; align-items: center;">
	<img title="wacv2025" style="float: left; margin-top: 25; padding-right: 1.5em; width: 300px; max-height: 100px;" src="/images/pub/wacv2025.png">
		<div>
			<b>PivotAlign: Improve Semi-Supervised Learning by Learning Intra-Class Heterogeneity and Aligning with Pivots</b><br>
			Lingjie Yi, Tao Sun, Yikai Zhang, Songzhu Zheng, <u>Weimin Lyu</u>, Haibin Ling, Chao Chen<br>
			<em>IEEE/CVF Winter Conference on Applications of Computer Vision (<b>WACV 2025</b>)</em> <br>
			<a href="https://openaccess.thecvf.com/content/WACV2025/papers/Yi_PivotAlign_Improve_Semi-Supervised_Learning_by_Learning_Intra-Class_Heterogeneity_and_Aligning_WACV_2025_paper.pdf" target="_blank" rel="WACV">[WACV]</a><br>
		</div>
	</div>
</div>



---




<!-- ECCV2024 -->
<!-- <div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto; ustify-content: center; align-items: center;">
	<img title="eccv2024" style="float: left; margin-top: 40px; padding-right: 1.5em; width: 300px; max-height: 100px;" src="/images/pub/eccv2024.jpg">
		<div> -->

<div style="margin-bottom: 0em; display: flex; flex-wrap: wrap; align-items: center; background-color: #fff; border: 0;">
	<div style="width: 300px; height: 100px; display: flex; align-items: center; justify-content: center; flex-shrink: 0; margin-right: 0.1em;">
		<img src="/images/pub/eccv2024.jpg" alt="ECCV2024" title="ECCV2024"
         style="max-width: 100%; max-height: 100%; object-fit: contain;" />
	</div>
	<div style="flex: 1; min-width: 200px;">
			<b>TrojVLM: Backdoor Attack Against Vision Language Models</b><br>
			<u>Weimin Lyu</u>, Lu Pang, Tengfei Ma, Haibin Ling, Chao Chen<br>
			<em>The 18th European Conference on Computer Vision (<b>ECCV 2024</b>)</em> <br>
			[<a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/08278.pdf" target="_blank" rel="ECCV">ECCV</a>]<br>
	</div>
</div>



---



<!-- AMIA2024 -->
<div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto; ustify-content: center; align-items: center;">
	<img title="amia2024" style="float: left; margin-top: 50px; padding-right: 1.5em; width: 300px; max-height: 100px;" src="/images/pub/amia2024.jpg">
		<div>
			<b>BadCLM: Backdoor Attack in Clinical Language Models for Electronic Health Records</b><br>
			<u>Weimin Lyu</u>, Zexin Bi, Fusheng Wang, Chao Chen<br>
			<em>American Medical Informatics Association Annual Symposium (<b>AMIA 2024</b>)</em> (<b style="color:red;">Best Student Paper Finalist</b>)<br>
			[<a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12099347/" target="_blank" rel="nofollow">arXiv</a>]<br>
		</div>
	</div>
</div>


---






<!-- NAACL2024 -->
<div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto; ustify-content: center; align-items: center;">
	<img title="naacl2024" style="float: left; margin-top: 40px; padding-right: 1.5em; width: 300px; max-height: 100px;" src="/images/pub/naacl2024_tabdet.jpg">
		<div>
			<b>Task-Agnostic Detector for Insertion-Based Backdoor Attacks</b><br>
			<u>Weimin Lyu</u>, Xiao Lin, Songzhu Zheng, Lu Pang, Haibin Ling, Susmit Jha, Chao Chen<br>
			<em>The Findings of 2024 Annual Conference of the North American Chapter of the Association for Computational Linguistics (<b>NAACL 2024</b>)</em> <br>
			[<a href="https://aclanthology.org/2024.findings-naacl.179/" target="_blank" rel="nofollow">NAACL</a>]<br>
		</div>
	</div>
</div>



---





<!-- Findings of EMNLP'23 -->
<div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto;">
	<img title="emnlp2023" style="float: left; padding-right: 1.5em; width: 300px; max-height: 100px;" src="/images/pub/emnlp2023.jpg">
		<div>
			<b>Attention-Enhancing Backdoor Attacks Against BERT-based Models</b><br>
			<u>Weimin Lyu</u>, Songzhu Zheng, Lu Pang, Haibin Ling, Chao Chen<br>
			<em>The Findings of 2023 Conference on Empirical Methods in Natural Language Processing (<b>EMNLP 2023</b>)</em> (A short version is accepted as <b style="color:red;">Oral</b> at ICLR 2023 Workshop on BANDS)<br>
			[<a href="https://aclanthology.org/2023.findings-emnlp.716.pdf" target="_blank" rel="nofollow">EMNLP</a>][<a href="https://github.com/weimin17/" target="_blank" rel="nofollow">Code</a>]<br>

		</div>
	</div>
</div>

---


<!-- ICLR 2023 Workshop on BANDS -->
<!-- <div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto;">
	<img title="emnlp2023" style="float: left; padding-right: 1.5em; width: 300px; max-height: 100px;" src="/images/pub/emnlp2023.jpg">
		<div>
			<b>On the Existence of a Trojaned Twin Model</b><br>
			Songzhu Zheng, Yikai Zhang, <u>Weimin Lyu</u>, Mayank Goswami, Anderson Schneider, Yuriy Nevmyvaka, Haibin Ling, Chao Chen<br>
			<em>(<b>ICLR 2023 Workshop on BANDS</b>), 2023</em><br>
			[<a href="https://openreview.net/pdf?id=w48XN5HwpV8" target="_blank" rel="nofollow">OpenReview</a>]<br>

		</div>
	</div>
</div>
 -->




<!-- AIIM -->
<div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto; ustify-content: center; align-items: center;">
	<img title="aiim2022" style="float: left; margin-top: 40px; padding-right: 1.5em; width: 300px; max-height: 100px;" src="/images/pub/aiim2022.jpg">
		<div>
			<b>An Integrated LSTM-HeteroRGNN Model for Interpretable Opioid Overdose Risk Prediction</b><br>
			Xinyu Dong, Rachel Wong, <u>Weimin Lyu</u>, Kayley Abell-Hart, Janos G Hajagos, Richard N Rosenthal, Chao Chen, Fusheng Wang<br>
			<em>Artificial Intelligence in Medicine (<b>AIIM 2022</b>)</em><br>
			[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9630306/" target="_blank" rel="nofollow">AIIM</a>]<br>
		</div>
	</div>
</div>


---

<!-- AMIA2022 -->
<div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto; ustify-content: center; align-items: center;">
	<img title="amia2022" style="float: left; margin-top: 50px; padding-right: 1.5em; width: 300px; max-height: 100px;" src="/images/pub/amia2022.jpg">
		<div>
			<b>A Multimodal Transformer: Fusing Clinical Notes With Structured EHR Data for Interpretable In-Hospital Mortality Prediction</b><br>
			<u>Weimin Lyu</u>, Xinyu Dong, Rachel Wong, Songzhu Zheng , Kayley Abell-Hart, Fusheng Wang, Chao Chen<br>
			<em>American Medical Informatics Association Annual Symposium (<b>AMIA 2022</b>)</em> (<b style="color:red;">Best Student Paper Finalist</b>)<br>
			[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10148371/" target="_blank" rel="nofollow">AMIA</a>][<a href="https://github.com/weimin17/Multimodal_Transformer" target="_blank" rel="nofollow">Code</a>]<br>
		</div>
	</div>
</div>


---


<!-- NAACL2022 -->
<div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto; ustify-content: center; align-items: center;">
	<img title="naacl2022" style="float: left; margin-top: 40px; padding-right: 1.5em; width: 300px; max-height: 100px;" src="/images/pub/naacl2022.jpg">
		<div>
			<b>A Study of the Attention Abnormality in Trojaned BERTs</b><br>
			<u>Weimin Lyu</u>, Songzhu Zheng, Tengfei Ma, Chao Chen<br>
			<em>The 2022 Conference of the North American Chapter of the Association for Computational Linguistics - Human Language Technologies (<b>NAACL 2022</b>)(<b style="color:red;">Oral</b>)</em> <br>
			[<a href="https://aclanthology.org/2022.naacl-main.348/" target="_blank" rel="nofollow">NAACL</a>][<a href="https://github.com/weimin17/attention_abnormality_in_trojaned_berts" target="_blank" rel="nofollow">Code</a>]<br>
		</div>
	</div>
</div>



---



<!-- ACL@Semeval2019 -->

<!-- 
<div style="margin-bottom: 1em; border: 0px solid #ddd; background-color: #fff">
	<div style="margin: 0px auto; ustify-content: center; align-items: center;">
	<img title="acl2019" style="float: left; margin-top: 30px; padding-right: 1.5em; width: 300px; max-height: 100px;" src="/images/pub/acl@seml2019.jpg">
		<div>
			<b>CUNY-PKU Parser at SemEval-2019 Task 1: Cross-Lingual Semantic Parsing with UCCA</b><br>
			<u>Weimin Lyu</u>, Sheng Huang, Abdul Rafae Khan, Shengqiang Zhang, Weiwei Sun, Jia Xu<br>
			<em>In Proceedings of the 13th International Workshop on Semantic Evaluation at Association for Computational Linguistics (<b>SemEval@ACL</b>), 2019</em> (<b style="color:red;">Student Scholarship</b>)<br>
			[<a href="https://aclanthology.org/S19-2012/" target="_blank" rel="nofollow">ACL</a>][<a href="https://github.com/weimin17/SemEval2019-task1" target="_blank" rel="nofollow">Code</a>]<br>
		</div>
	</div>
</div>

 -->
